{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"us political volatility.ipynb","provenance":[],"mount_file_id":"1jGBghtsv7dN-FkWxwVHbKXDSkAyfY_Mo","authorship_tag":"ABX9TyPNsaNQECQ4lTeCcy4jXH2e"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"0ErIH48IsuCk","colab_type":"code","outputId":"008babdf-76f2-4383-d9a7-49ea863a28e3","executionInfo":{"status":"ok","timestamp":1589639307693,"user_tz":-120,"elapsed":608,"user":{"displayName":"Karim Galal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9blvWWLtJOMHhvlAPLO7oU8wn2zs1v3EBmr3udA=s64","userId":"08944710229728524461"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, Bidirectional, Dropout, LSTM, BatchNormalization\n","from tensorflow.keras.datasets import imdb\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing.text import Tokenizer\n","from sklearn.preprocessing import LabelEncoder\n","\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from collections import Counter\n","import nltk\n","from nltk.corpus import stopwords\n","from  nltk.stem import SnowballStemmer\n","import gensim\n","from sklearn.model_selection import train_test_split\n","import re\n","nltk.download('stopwords')\n","decode_map = {0: \"NEGATIVE\", 1: \"POSITIVE\", 4: \"POSITIVE\"}\n","TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n","def decode_sentiment(label):\n","    return decode_map[int(label)]\n","def preprocess(text, stem=False):\n","    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n","    tokens = []\n","    for token in text.split():\n","        if token not in stop_words:\n","            if stem:\n","                tokens.append(stemmer.stem(token))\n","            else:\n","                tokens.append(token)\n","    return \" \".join(tokens)\n","POSITIVE = \"POSITIVE\"\n","NEGATIVE = \"NEGATIVE\"\n","NEUTRAL = \"NEUTRAL\"\n","SEQUENCE_LENGTH = 150\n","SENTIMENT_THRESHOLDS = (0.4, 0.6)\n","TRAIN_SIZE=0.55\n","EPOCHS = 8\n","BATCH_SIZE = 64\n","KERAS_MODEL = \"model.h5\"\n","WORD2VEC_MODEL = \"model.w2v\"\n","TOKENIZER_MODEL = \"tokenizer.pkl\"\n","ENCODER_MODEL = \"encoder.pkl\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KLylYF3TyCCC","colab_type":"code","outputId":"157d5360-c34e-44bc-fe27-13808a3037ff","executionInfo":{"status":"ok","timestamp":1589646599677,"user_tz":-120,"elapsed":573,"user":{"displayName":"Karim Galal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9blvWWLtJOMHhvlAPLO7oU8wn2zs1v3EBmr3udA=s64","userId":"08944710229728524461"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["df = pd.read_csv('news_data.csv')\n","stop_words = stopwords.words(\"english\")\n","stemmer = SnowballStemmer(\"english\")\n","df.titles = df.titles.apply(lambda x: preprocess(x))\n","df.target = df.target.apply(lambda x: decode_sentiment(x))\n","\n","df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n","print(\"TRAIN size:\", len(df_train))\n","print(\"TEST size:\", len(df_test))\n","counts = dict(Counter(df_train.target))\n","print(counts)"],"execution_count":71,"outputs":[{"output_type":"stream","text":["TRAIN size: 153\n","TEST size: 39\n","{'POSITIVE': 78, 'NEGATIVE': 75}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qBsLHkXYBsf1","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"gZg8Dv0A6_XG","colab_type":"code","outputId":"0d30d53d-a362-453e-821d-d7fdfdd2a85a","executionInfo":{"status":"ok","timestamp":1589640016922,"user_tz":-120,"elapsed":45445,"user":{"displayName":"Karim Galal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9blvWWLtJOMHhvlAPLO7oU8wn2zs1v3EBmr3udA=s64","userId":"08944710229728524461"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["!mkdir ~/.kaggle\n","!cp kaggle.json ~/.kaggle/kaggle.json\n","!chmod 600 ~/.kaggle/kaggle.json\n","!pip -q install gensim --upgrade\n","!rm -r sample_data\n","!kaggle datasets download rtatman/glove-global-vectors-for-word-representation\n","!unzip -q glove-global-vectors-for-word-representation"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 24.2MB 158kB/s \n","\u001b[?25hDownloading glove-global-vectors-for-word-representation.zip to /content\n"," 99% 454M/458M [00:12<00:00, 41.7MB/s]\n","100% 458M/458M [00:12<00:00, 39.4MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EqSTHbLC7WPC","colab_type":"code","outputId":"04c809ae-3a5b-41b2-dcfb-986b5850a798","executionInfo":{"status":"ok","timestamp":1589640139461,"user_tz":-120,"elapsed":83859,"user":{"displayName":"Karim Galal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9blvWWLtJOMHhvlAPLO7oU8wn2zs1v3EBmr3udA=s64","userId":"08944710229728524461"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["from gensim.models import KeyedVectors\n","from gensim.scripts.glove2word2vec import glove2word2vec\n","glove2word2vec(glove_input_file=\"glove.6B.200d.txt\", word2vec_output_file=\"model.w2v\")\n","w2v_model = KeyedVectors.load_word2vec_format('model.w2v')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vya0jqz87q-4","colab_type":"code","outputId":"5ea51693-8314-426c-d93c-173415cd19d7","executionInfo":{"status":"ok","timestamp":1589641618215,"user_tz":-120,"elapsed":481,"user":{"displayName":"Karim Galal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9blvWWLtJOMHhvlAPLO7oU8wn2zs1v3EBmr3udA=s64","userId":"08944710229728524461"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["documents = [_text.split() for _text in df_train.titles] \n","W2V_SIZE = 200\n","W2V_WINDOW = 7\n","W2V_EPOCH = 2\n","W2V_MIN_COUNT = 10\n","\n","words = w2v_model.wv.vocab.keys()\n","vocab_size = len(words)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  import sys\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"4tFwESW573Hw","colab_type":"code","colab":{}},"source":["import pickle\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(df_train.titles)\n","vocab_size = len(tokenizer.word_index) + 1\n","x_train = pad_sequences(tokenizer.texts_to_sequences(df_train.titles), maxlen=SEQUENCE_LENGTH)\n","x_test = pad_sequences(tokenizer.texts_to_sequences(df_test.titles), maxlen=SEQUENCE_LENGTH)\n","labels = df_train.target.unique().tolist()\n","labels.append(NEUTRAL)\n","encoder = LabelEncoder()\n","encoder.fit(df_train.target.tolist())\n","\n","y_train = encoder.transform(df_train.target.tolist())\n","y_test = encoder.transform(df_test.target.tolist())\n","\n","y_train = y_train.reshape(-1,1)\n","y_test = y_test.reshape(-1,1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vxlk6O5k8LsW","colab_type":"code","outputId":"d23cb633-b45b-44c0-8ba5-0cf892b91c02","executionInfo":{"status":"ok","timestamp":1589646621528,"user_tz":-120,"elapsed":5036,"user":{"displayName":"Karim Galal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9blvWWLtJOMHhvlAPLO7oU8wn2zs1v3EBmr3udA=s64","userId":"08944710229728524461"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["print(\"x_train\", x_train.shape)\n","print(\"y_train\", y_train.shape)\n","print()\n","print(\"x_test\", x_test.shape)\n","print(\"y_test\", y_test.shape)"],"execution_count":74,"outputs":[{"output_type":"stream","text":["x_train (153, 150)\n","y_train (153, 1)\n","\n","x_test (39, 150)\n","y_test (39, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PAiv79YJ8NOd","colab_type":"code","outputId":"e9306ac9-876b-4d89-f8d1-2a773adfa4d8","executionInfo":{"status":"ok","timestamp":1589647039198,"user_tz":-120,"elapsed":1239,"user":{"displayName":"Karim Galal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9blvWWLtJOMHhvlAPLO7oU8wn2zs1v3EBmr3udA=s64","userId":"08944710229728524461"}},"colab":{"base_uri":"https://localhost:8080/","height":392}},"source":["embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n","from tensorflow.keras.optimizers import Adam, Nadam\n","\n","for word, i in tokenizer.word_index.items():\n","  if word in w2v_model.wv:\n","    embedding_matrix[i] = w2v_model.wv[word]\n","\n","embedding_layer = Embedding(vocab_size, W2V_SIZE, weights=[embedding_matrix], input_length=SEQUENCE_LENGTH, trainable=False)\n","\n","model = Sequential()\n","model.add(embedding_layer)\n","model.add(Dropout(0.3))\n","model.add(Bidirectional(LSTM(20, dropout=0.35, recurrent_dropout=0.35, return_sequences=False)))\n","model.add(Dense(2, activation='softmax'))\n","model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer=Nadam(lr=1e-15),\n","              metrics=['accuracy'])\n","model.summary()"],"execution_count":77,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \"\"\"\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_16 (Embedding)     (None, 150, 200)          778800    \n","_________________________________________________________________\n","dropout_16 (Dropout)         (None, 150, 200)          0         \n","_________________________________________________________________\n","bidirectional_30 (Bidirectio (None, 40)                35360     \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 2)                 82        \n","=================================================================\n","Total params: 814,242\n","Trainable params: 35,442\n","Non-trainable params: 778,800\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yiYy9abb8a2J","colab_type":"code","outputId":"2a50dae4-4eb1-436b-c479-d4fb9eae0542","executionInfo":{"status":"ok","timestamp":1589647072515,"user_tz":-120,"elapsed":26399,"user":{"displayName":"Karim Galal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9blvWWLtJOMHhvlAPLO7oU8wn2zs1v3EBmr3udA=s64","userId":"08944710229728524461"}},"colab":{"base_uri":"https://localhost:8080/","height":247}},"source":["model.fit(x_train,y_train,batch_size=10,epochs=6)"],"execution_count":78,"outputs":[{"output_type":"stream","text":["Epoch 1/6\n","16/16 [==============================] - 3s 207ms/step - loss: 0.6950 - accuracy: 0.5490\n","Epoch 2/6\n","16/16 [==============================] - 3s 204ms/step - loss: 0.7146 - accuracy: 0.4771\n","Epoch 3/6\n","16/16 [==============================] - 3s 200ms/step - loss: 0.7133 - accuracy: 0.4248\n","Epoch 4/6\n","16/16 [==============================] - 3s 204ms/step - loss: 0.7183 - accuracy: 0.4575\n","Epoch 5/6\n","16/16 [==============================] - 3s 208ms/step - loss: 0.7131 - accuracy: 0.4902\n","Epoch 6/6\n","16/16 [==============================] - 3s 207ms/step - loss: 0.6980 - accuracy: 0.5556\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fd0098510b8>"]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"code","metadata":{"id":"nzo58jA29rza","colab_type":"code","outputId":"c22da66d-5c68-443a-c11a-1721bc2314b8","executionInfo":{"status":"ok","timestamp":1589647099393,"user_tz":-120,"elapsed":2437,"user":{"displayName":"Karim Galal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9blvWWLtJOMHhvlAPLO7oU8wn2zs1v3EBmr3udA=s64","userId":"08944710229728524461"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["model.evaluate(x_test,y_test)\n","one_good = 0\n","one_bad = 0\n","good = 0\n","bad=0\n","for i,j in zip(x_test,y_test):\n","  true = j[0]\n","  predict = np.argmax(model.predict(np.array([i])))\n","  if true == 0:\n","    if predict == 0:\n","      good+=1\n","    else:\n","      bad +=1\n","  else:\n","    if predict == 1:\n","      one_good+=1\n","    else:\n","      one_bad+=1\n","print(good,bad)\n","print(one_good,one_bad)"],"execution_count":80,"outputs":[{"output_type":"stream","text":["2/2 [==============================] - 0s 19ms/step - loss: 0.6887 - accuracy: 0.5641\n","12 9\n","10 8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6LliqKCWWepc","colab_type":"code","colab":{}},"source":["model.save('news_model.h5')"],"execution_count":0,"outputs":[]}]}